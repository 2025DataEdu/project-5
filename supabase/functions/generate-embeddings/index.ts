
import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.50.1';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    console.log('ğŸš€ Starting generate-embeddings function');
    
    const openAIApiKey = Deno.env.get('OPENAI_API_KEY');
    const supabaseUrl = Deno.env.get('SUPABASE_URL');
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');

    if (!openAIApiKey) {
      throw new Error('OpenAI API key not configured');
    }

    const supabase = createClient(supabaseUrl!, supabaseServiceKey!);
    
    // ì „ì²´ ë¬¸ì„œ ìˆ˜ í™•ì¸
    console.log('ğŸ“Š Checking total document count...');
    const { count: totalCount } = await supabase
      .from('ê²°ì¬ë¬¸ì„œëª©ë¡')
      .select('*', { count: 'exact', head: true });

    console.log(`ğŸ“„ Total documents in database: ${totalCount}`);

    // ì´ë¯¸ ì„ë² ë”©ì´ ìƒì„±ëœ ë¬¸ì„œ IDë“¤ ê°€ì ¸ì˜¤ê¸°
    const { data: existingEmbeddings } = await supabase
      .from('document_embeddings')
      .select('document_id');

    const existingDocIds = new Set(existingEmbeddings?.map(e => e.document_id) || []);
    console.log(`âœ… Existing embeddings: ${existingDocIds.size}`);

    // ì„ë² ë”©ì´ ì—†ëŠ” ë¬¸ì„œë“¤ë§Œ ê°€ì ¸ì˜¤ê¸° (ë” í° ë°°ì¹˜ í¬ê¸°)
    const batchSize = 200;
    let offset = 0;
    let totalProcessed = 0;
    let totalErrors = 0;
    let batchCount = 0;
    
    while (true) {
      batchCount++;
      console.log(`ğŸ“„ Processing batch ${batchCount} (offset: ${offset})...`);
      
      const { data: documents, error: fetchError } = await supabase
        .from('ê²°ì¬ë¬¸ì„œëª©ë¡')
        .select('*')
        .range(offset, offset + batchSize - 1);

      if (fetchError) {
        console.error('âŒ Error fetching documents:', fetchError);
        throw fetchError;
      }

      if (!documents || documents.length === 0) {
        console.log('ğŸ No more documents to process');
        break;
      }

      console.log(`ğŸ“Š Batch ${batchCount}: ${documents.length} documents fetched`);

      // ì´ë¯¸ ì„ë² ë”©ì´ ìˆëŠ” ë¬¸ì„œ í•„í„°ë§
      const documentsToProcess = documents.filter(doc => !existingDocIds.has(doc.id));
      console.log(`ğŸ” Batch ${batchCount}: ${documentsToProcess.length} documents need embeddings`);

      if (documentsToProcess.length === 0) {
        console.log(`âš ï¸ Batch ${batchCount}: All documents already have embeddings, skipping...`);
        offset += batchSize;
        continue;
      }

      // ë°°ì¹˜ ë‚´ì—ì„œ ë³‘ë ¬ ì²˜ë¦¬ (ë™ì‹œ ì²˜ë¦¬ ìˆ˜ ì œí•œ)
      const concurrentLimit = 5;
      for (let i = 0; i < documentsToProcess.length; i += concurrentLimit) {
        const batch = documentsToProcess.slice(i, i + concurrentLimit);
        const promises = batch.map(async (doc) => {
          try {
            // í…ìŠ¤íŠ¸ ì¤€ë¹„ (ì œëª© + ë¶€ì„œëª…)
            const textToEmbed = `${doc.ì œëª© || ''} ${doc.ì „ì²´ë¶€ì„œëª… || ''}`.trim();
            
            if (!textToEmbed) {
              console.log(`âš ï¸ Skipping document ${doc.id} - no text content`);
              return { success: false, reason: 'no_text' };
            }

            console.log(`ğŸ”¤ Processing doc ${doc.id}: "${textToEmbed.substring(0, 30)}..."`);

            // OpenAI ì„ë² ë”© ìƒì„±
            const embeddingResponse = await fetch('https://api.openai.com/v1/embeddings', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${openAIApiKey}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                model: 'text-embedding-ada-002',
                input: textToEmbed,
              }),
            });

            if (!embeddingResponse.ok) {
              const errorText = await embeddingResponse.text();
              console.error(`âŒ OpenAI API error for doc ${doc.id}:`, errorText);
              return { success: false, reason: 'openai_error', error: errorText };
            }

            const embeddingData = await embeddingResponse.json();
            const embedding = embeddingData.data[0].embedding;

            // ì„ë² ë”©ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            const { error: insertError } = await supabase
              .from('document_embeddings')
              .insert({
                document_id: doc.id,
                document_title: doc.ì œëª© || 'ì œëª© ì—†ìŒ',
                document_type: 'ê²°ì¬ë¬¸ì„œ',
                department: doc.ì „ì²´ë¶€ì„œëª…,
                content_text: textToEmbed,
                embedding: embedding,
              });

            if (insertError) {
              console.error(`âŒ Error inserting embedding for doc ${doc.id}:`, insertError);
              return { success: false, reason: 'insert_error', error: insertError };
            }

            console.log(`âœ… Successfully processed document ${doc.id}`);
            return { success: true };

          } catch (docError) {
            console.error(`ğŸ’¥ Error processing document ${doc.id}:`, docError);
            return { success: false, reason: 'exception', error: docError };
          }
        });

        // ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼ ìˆ˜ì§‘
        const results = await Promise.all(promises);
        const successful = results.filter(r => r.success).length;
        const failed = results.filter(r => !r.success).length;
        
        totalProcessed += successful;
        totalErrors += failed;

        console.log(`ğŸ“ˆ Mini-batch completed: ${successful} success, ${failed} failed (Total: ${totalProcessed} processed, ${totalErrors} errors)`);

        // API ë ˆì´íŠ¸ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
        if (i + concurrentLimit < documentsToProcess.length) {
          await new Promise(resolve => setTimeout(resolve, 100));
        }
      }

      // ë‹¤ìŒ ë°°ì¹˜ë¡œ ì´ë™
      offset += batchSize;
      
      // ì§„í–‰ ìƒí™© ë¡œê·¸
      const progress = Math.round((totalProcessed / (totalCount || 1)) * 100);
      console.log(`ğŸ“Š Batch ${batchCount} completed. Overall progress: ${totalProcessed}/${totalCount} (${progress}%) processed, ${totalErrors} errors`);

      // ì¤‘ê°„ ì§„í–‰ ìƒí™© ì²´í¬ (ë„ˆë¬´ ë§ì€ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì¤‘ë‹¨)
      if (totalErrors > 100) {
        console.log('âš ï¸ Too many errors, stopping batch processing');
        break;
      }
    }

    console.log(`ğŸ Embedding generation completed: ${totalProcessed} processed, ${totalErrors} errors`);

    return new Response(JSON.stringify({ 
      success: true, 
      processed: totalProcessed,
      errors: totalErrors,
      total: totalCount || 0,
      existing: existingDocIds.size,
      message: `ì„ë² ë”© ìƒì„± ì™„ë£Œ: ${totalProcessed}ê°œ ì‹ ê·œ ì²˜ë¦¬, ${totalErrors}ê°œ ì˜¤ë¥˜`
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error) {
    console.error('ğŸ’¥ Function error:', error);
    return new Response(JSON.stringify({ 
      error: error.message,
      success: false,
      message: `ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ${error.message}`
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
});
